"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9842],{65534:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var a=n(87462),o=(n(67294),n(3905));n(8209);const i={title:"3 - Node.js Example"},r=void 0,s={unversionedId:"guides/kafka/nodejs",id:"guides/kafka/nodejs",isDocsHomePage:!1,title:"3 - Node.js Example",description:"In this section we will listen to Kafka events and pipe them to commandline process stdout.",source:"@site/docs/common/guides/kafka/3-nodejs.md",sourceDirName:"guides/kafka",slug:"/guides/kafka/nodejs",permalink:"/common/guides/kafka/nodejs",editUrl:"https://github.com/getditto/docs/edit/main/docs/common/guides/kafka/3-nodejs.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"3 - Node.js Example"},sidebar:"defaultSidebar",previous:{title:"2 - Ditto events",permalink:"/common/guides/kafka/consumer"},next:{title:"Overview",permalink:"/common/security/overview"}},c=[{value:"Prequisites",id:"prequisites",children:[],level:2},{value:"Code Sample",id:"code-sample",children:[],level:2},{value:"Converting Certificates to the proper formats",id:"converting-certificates-to-the-proper-formats",children:[],level:2},{value:"Decoding transactions",id:"decoding-transactions",children:[{value:"Checking <code>transaction.type</code>",id:"checking-transactiontype",children:[],level:3}],level:2},{value:"Parsing <code>documentChanged</code> events",id:"parsing-documentchanged-events",children:[{value:"Inserting a new document",id:"inserting-a-new-document",children:[],level:3},{value:"Updating an existing document",id:"updating-an-existing-document",children:[],level:3},{value:"Removing a document",id:"removing-a-document",children:[],level:3}],level:2},{value:"Parsing <code>requeryRequired</code> event",id:"parsing-requeryrequired-event",children:[],level:2},{value:"Code Sample",id:"code-sample-1",children:[],level:2}],l={toc:c},d="wrapper";function u(e){let{components:t,...i}=e;return(0,o.kt)(d,(0,a.Z)({},l,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"In this section we will listen to Kafka events and pipe them to commandline process ",(0,o.kt)("inlineCode",{parentName:"p"},"stdout"),". "),(0,o.kt)("h2",{id:"prequisites"},"Prequisites"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"An instance of MongoDB."),(0,o.kt)("li",{parentName:"ul"},"Basic understanding of Node.js."),(0,o.kt)("li",{parentName:"ul"},"Local installation of ",(0,o.kt)("a",{parentName:"li",href:"https://nodejs.org/en/"},"Node 16"),". "),(0,o.kt)("li",{parentName:"ul"},"A Ditto application syncing with the Big Peer on the ",(0,o.kt)("a",{parentName:"li",href:"https://portal.ditto.live/"},"Ditto Portal")," that is on a dedicated cluster.")),(0,o.kt)("h2",{id:"code-sample"},"Code Sample"),(0,o.kt)("p",null,"See the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/getditto/external-sync/tree/main/nodejs-mongo"},"github repository")," for example code to connect a Node.js instance to the Ditto Big peer as a Kafka sink to MongoDB."),(0,o.kt)("h2",{id:"converting-certificates-to-the-proper-formats"},"Converting Certificates to the proper formats"),(0,o.kt)("p",null,"First, you must download the proper Kafka certficiates and convert them to the format required by SSL via Node.js. "),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"kafka credentials",src:n(13060).Z})),(0,o.kt)("p",null,"Convert the .p12 files to the required user.key, cluster.crt, and user.crt files. When propmted, use the appropriate cluster certficiate password or user password as described in the portal."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"\u276f openssl pkcs12 -in cluster.p12 -out cluster.crt.pem -nokeys\n\u276f openssl x509 -in cluster.crt.pem -out cluster.crt\n\u276f openssl pkcs12 -in user.p12 -out user.crt -clcerts\n\u276f openssl pkcs12 -in user.p12 -out user.key.pem -nocerts\n\u276f openssl pkey -in user.key.pem -out user.key\n")),(0,o.kt)("h2",{id:"decoding-transactions"},"Decoding transactions"),(0,o.kt)("p",null,"All messages from the Ditto CDC are sent to your Kafka sink as JSON. First, you must decode the transaction as JSON. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"try {\n    const transaction = JSON.parse(message.value!.toString())\n    parseTransaction(database, transaction).then(() => {\n        // Success!\n    }).catch(err => {\n        console.error('[ERROR] Got error when parsing transaction', err)\n    })\n} catch (err) {\n    console.error(\"[ERROR]: Failed to parse change\", change)\n}\n")),(0,o.kt)("h3",{id:"checking-transactiontype"},"Checking ",(0,o.kt)("inlineCode",{parentName:"h3"},"transaction.type")),(0,o.kt)("p",null,"Each transaction has a type -- Ditto has two types, ",(0,o.kt)("inlineCode",{parentName:"p"},"requeryRequired")," and\n",(0,o.kt)("inlineCode",{parentName:"p"},"documentChanged"),". "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"async function parseTransaction (database: Db, transaction: DittoTransaction) {\n  const collectionName = transaction.collection\n  const collection = database.collection(collectionName);\n\n  switch (transaction.type) {\n    case 'requeryRequired':\n        onRequeryRequired()\n      return;\n    case 'documentChanged':\n        onDocumentChanged()\n    default: \n      break;\n  }\n}\n")),(0,o.kt)("h2",{id:"parsing-documentchanged-events"},"Parsing ",(0,o.kt)("inlineCode",{parentName:"h2"},"documentChanged")," events"),(0,o.kt)("p",null,"For the ",(0,o.kt)("inlineCode",{parentName:"p"},"onDocumentChanged")," function, we will parse the event into one of three possible types: Insert, Update, and Remove"),(0,o.kt)("h3",{id:"inserting-a-new-document"},"Inserting a new document"),(0,o.kt)("p",null,"When ",(0,o.kt)("inlineCode",{parentName:"p"},"change.oldValue")," is equal to ",(0,o.kt)("inlineCode",{parentName:"p"},"null"),", that means that a new document was inserted into the database. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"if (transaction.change.method === 'update' && transaction.change.oldValue === null) {\n  let change: DittoInsert = transaction.change\n  const result = await collection.insertOne(change.newValue);\n  console.log(\n   `A document was inserted with the _id: ${result.insertedId}`,\n  );\n}\n")),(0,o.kt)("h3",{id:"updating-an-existing-document"},"Updating an existing document"),(0,o.kt)("p",null,"If ",(0,o.kt)("inlineCode",{parentName:"p"},"change.oldValue")," has a value, that means that a document with the corresponding ",(0,o.kt)("inlineCode",{parentName:"p"},"_id")," was updated to the value indicated in ",(0,o.kt)("inlineCode",{parentName:"p"},"change.newValue"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"if (transaction.change.method === 'upsert' && oldValue !== null) {\n    let change: DittoUpdate = transaction.change\n    const _id = change.oldValue._id\n    const filter = { _id };\n    const result = await collection.replaceOne(filter, change.newValue, {upsert: true});\n    console.log(\n        `${result.matchedCount} document(s) matched the filter, updated ${result.modifiedCount} document(s)`,\n    );\n}\n")),(0,o.kt)("h3",{id:"removing-a-document"},"Removing a document"),(0,o.kt)("p",null,"When ",(0,o.kt)("inlineCode",{parentName:"p"},"change.method")," is equal to ",(0,o.kt)("inlineCode",{parentName:"p"},'"remove"'),", then the document has been deleted from Ditto."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"if (transaction.change.method === 'remove') {\n    let change: DittoRemove = transaction.change\n    const _id = transaction.change.value._id\n    const filter = { _id };\n    const result = await collection.deleteOne(filter)\n    console.log(\n    `${result.deletedCount} document(s) matched the filter`,\n    );\n}\n")),(0,o.kt)("h2",{id:"parsing-requeryrequired-event"},"Parsing ",(0,o.kt)("inlineCode",{parentName:"h2"},"requeryRequired")," event"),(0,o.kt)("p",null,"Send an HTTP request to tell the Ditto Big Peer to catch up to the given\ntransaction id as part of ",(0,o.kt)("inlineCode",{parentName:"p"},"transaction.txnId")," and the given ",(0,o.kt)("inlineCode",{parentName:"p"},"collection"),". "),(0,o.kt)("p",null,"Your HTTP Endpoint will look like ",(0,o.kt)("inlineCode",{parentName:"p"},"https://${APP_ID}.cloud.ditto.live")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},"function onRequeryRequired (database: Db, transaction: DittoRequeryRequired) {\n  const HTTP_ENDPOINT = httpEndpoint + '/api/v3/store/find'\n  for (const requeryDoc of transaction.documents) {\n    const req = {\n      method: 'post',\n      url: HTTP_ENDPOINT,\n      headers: {\n        'Content-Type': 'application/json',\n        'X-DITTO-TXN-ID': transaction.txnId\n      }, \n      data: {\n        \"collection\": transaction,\n        \"query\": \"true\",\n        \"limit\": 1\n      }\n    }\n\n    axios(req).then(function (response) {\n      if (response.data.message) {\n        // ERROR\n      } else {\n        for (const doc of response.data.documents) {\n          // Insert updated docs\n          const mongodbCollection = database.collection(requeryDoc.collectionName);\n          let missingDocument = doc as DittoHTTPDocument \n          mongodbCollection.replaceOne({_id: missingDocument.id}, missingDocument)\n        }\n      }\n    }).catch(err => {\n      console.error(`[ERROR]: HTTP find request ${req}`)\n      console.error(err)\n    });\n}\n")),(0,o.kt)("h2",{id:"code-sample-1"},"Code Sample"),(0,o.kt)("p",null,"See the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/getditto/external-sync/tree/main/nodejs-mongo"},"github repository")," for the full example Node.js code."))}u.isMDXComponent=!0},13060:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/kafka-browser-fc06d4e4570b17e09d3b114112159160.png"}}]);